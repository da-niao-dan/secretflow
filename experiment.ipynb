{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_parties_number = 2\n",
    "edge_party_name = 'edge_party_{i}'\n",
    "edge_parties = [edge_party_name.format(i=i) for i in range(edge_parties_number)]\n",
    "server_party_name = 'server_party'\n",
    "server_party = [server_party_name]\n",
    "all_parties = edge_parties + server_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge_party_0', 'edge_party_1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoupeicheng.zpc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-13 17:10:31,087\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-13 17:10:31,257\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/zoupeicheng.zpc/miniconda3/envs/py310/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2024-12-13 17:10:33,184\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "sf.init(parties=all_parties, address='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_devices = [sf.PYU(edge_party_name.format(i=i)) for i in range(edge_parties_number)]\n",
    "# use pyu to simulate teeu\n",
    "edge_tees = [sf.PYU(edge_party_name.format(i=i)) for i in range(edge_parties_number)]\n",
    "\n",
    "server_device = sf.PYU(server_party_name)\n",
    "server_tee = sf.PYU(server_party_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom parameters\n",
    "i = 0\n",
    "j = 1\n",
    "m = 100\n",
    "kappa = 32\n",
    "u_low = 0.0\n",
    "u_high = 2.0\n",
    "# k is the ring size 2^k. usually take k = 32, 64. like size of int\n",
    "k = 64  # implies use uint64\n",
    "fxp = 26  # fixed point precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original JAX Array:\n",
      "[0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0\n",
      " 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1]\n",
      "uint64\n",
      "\n",
      "Decrypted JAX Array:\n",
      "[0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0\n",
      " 1 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1]\n",
      "uint64\n",
      "\n",
      "Arrays are equal: True\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from typing import Tuple\n",
    "import hashlib\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "def bytes_to_jax_random_key(byte_key):\n",
    "    seed = int.from_bytes(byte_key[:4], 'big')\n",
    "\n",
    "    # Create a JAX random key with this seed\n",
    "    jax_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    return jax_key\n",
    "\n",
    "\n",
    "# Function to encrypt a jnp array using AES-GCM\n",
    "def encrypt_jnp_array_gcm(jnp_array, key) -> Tuple[bytes, bytes, bytes]:\n",
    "\n",
    "    # Convert numpy array to bytes\n",
    "    array_bytes = jnp_array.tobytes()\n",
    "\n",
    "    # Create AES cipher in GCM mode\n",
    "    cipher = AES.new(key, AES.MODE_GCM)\n",
    "\n",
    "    # Encrypt data\n",
    "    ciphertext, tag = cipher.encrypt_and_digest(array_bytes)\n",
    "\n",
    "    # Return the ciphertext, tag, and nonce\n",
    "    return ciphertext, tag, cipher.nonce\n",
    "\n",
    "\n",
    "# Function to decrypt a jnp array using AES-GCM\n",
    "def decrypt_to_jnp_array_gcm(ciphertext, tag, nonce, key, dtype, shape):\n",
    "    # Create AES cipher in GCM mode with the same parameters\n",
    "    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n",
    "\n",
    "    # Decrypt data\n",
    "    decrypted_data = cipher.decrypt_and_verify(ciphertext, tag)\n",
    "\n",
    "    # Convert bytes back to numpy array\n",
    "    decrypted_jnp_array = jnp.frombuffer(decrypted_data, dtype=dtype).reshape(shape)\n",
    "\n",
    "    return decrypted_jnp_array\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a random key for AES-256 (32 bytes)\n",
    "    key = get_random_bytes(32)\n",
    "\n",
    "    # Create a jnp array\n",
    "    original_jnp_array = jnp.uint64(\n",
    "        jnp.array(np.random.uniform(u_low, u_high, (m,)), dtype=jnp.float64)\n",
    "    )\n",
    "\n",
    "    # Encrypt the jnp array using AES-GCM\n",
    "    ciphertext, tag, nonce = encrypt_jnp_array_gcm(original_jnp_array, key)\n",
    "\n",
    "    # Decrypt to a jnp array\n",
    "    decrypted_jnp_array = decrypt_to_jnp_array_gcm(\n",
    "        ciphertext, tag, nonce, key, dtype=jnp.uint64, shape=original_jnp_array.shape\n",
    "    )\n",
    "\n",
    "    # Check if the original and decrypted arrays are the same\n",
    "    print(\"Original JAX Array:\")\n",
    "    print(original_jnp_array)\n",
    "    print(original_jnp_array.dtype)\n",
    "    print(\"\\nDecrypted JAX Array:\")\n",
    "    print(decrypted_jnp_array)\n",
    "    print(decrypted_jnp_array.dtype)\n",
    "    print(\n",
    "        \"\\nArrays are equal:\", jnp.array_equal(original_jnp_array, decrypted_jnp_array)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float mul a * b 1000000\n",
      "67108864000\n",
      "67108864000\n",
      "fxp mul without scaling:  2594073385365405696\n",
      "fxp mul with scaling but float:  4.503599627370496e+21\n",
      "38654705664.0\n"
     ]
    }
   ],
   "source": [
    "def fxp_mul(a, b):\n",
    "    return a * b\n",
    "\n",
    "\n",
    "fxp_type = jnp.uint64\n",
    "a = 1000\n",
    "b = 1000\n",
    "fxp = 26\n",
    "print(\"float mul a * b\", a * b)\n",
    "a_fxp = fxp_type(a * 2.0**fxp)\n",
    "b_fxp = fxp_type(b * 2.0**fxp)\n",
    "\n",
    "print(a_fxp)\n",
    "print(b_fxp)\n",
    "print(\"fxp mul without scaling: \", a_fxp * b_fxp)\n",
    "\n",
    "print(\"fxp mul with scaling but float: \", a_fxp* 1.0 * (b_fxp*1.0))\n",
    "\n",
    "print(fxp_mul(a_fxp, b_fxp) / 2.0 ** (fxp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "set_ups = [\n",
    "    edge_devices[i](lambda: jax.config.update(\"jax_enable_x64\", True))(),\n",
    "    edge_devices[j](lambda: jax.config.update(\"jax_enable_x64\", True))(),\n",
    "    server_device(lambda: jax.config.update(\"jax_enable_x64\", True))(),\n",
    "    edge_tees[i](lambda: jax.config.update(\"jax_enable_x64\", True))(),\n",
    "    edge_tees[j](lambda: jax.config.update(\"jax_enable_x64\", True))(),\n",
    "    server_tee(lambda: jax.config.update(\"jax_enable_x64\", True))(),\n",
    "]\n",
    "sf.wait(set_ups)\n",
    "\n",
    "# Simulate handles\n",
    "\n",
    "handle_i_j = edge_tees[i](lambda x: get_random_bytes(x))(kappa)\n",
    "handle_i_s = edge_tees[i](lambda x: get_random_bytes(x))(kappa)\n",
    "\n",
    "# note that the establishment is not simplified.\n",
    "handle_j_i = handle_i_j.to(edge_tees[j])\n",
    "handle_j_s = edge_tees[j](lambda x: get_random_bytes(x))(kappa)\n",
    "\n",
    "server_handle_i_s = handle_i_s.to(server_tee)\n",
    "server_handle_j_s = handle_j_s.to(server_tee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_i holds u_i\n",
    "u_i = edge_devices[i](lambda x: x)(jnp.array(np.random.uniform(u_low, u_high, (m,))))\n",
    "\n",
    "# P_j holds u_j\n",
    "u_j = edge_devices[j](lambda x: x)(jnp.array(np.random.uniform(u_low, u_high, (m,))))\n",
    "\n",
    "\n",
    "# corr preprocessing\n",
    "def corr(k, m, dev1, key1, dev2, key2, return_zero_sharing=False):\n",
    "    \"\"\"Correlation function\n",
    "\n",
    "    Args:\n",
    "        k (int): ring size will be 2^k. Support k = 64 or 128 for now\n",
    "        m (int): size of array to be correlated\n",
    "        dev1 (Device): device 1\n",
    "        key1 (Key): key for device 1\n",
    "        dev2 (Device): device 2\n",
    "        key2 (Key): key for device 2, key2 must be the same as key1 yet hold by different device\n",
    "    \"\"\"\n",
    "    assert k == 64, \"Only support k = 64 for now\"\n",
    "    dtype = jnp.uint64\n",
    "    corr_dev1 = dev1(\n",
    "        lambda key, shape, dtype: dtype(jax.random.bits(\n",
    "            bytes_to_jax_random_key(key), shape)\n",
    "        )\n",
    "    )(key1, (m,), dtype)\n",
    "    if not return_zero_sharing:\n",
    "        corr_dev2 = dev2(\n",
    "            lambda key, shape, dtype: dtype(jax.random.bits(\n",
    "                bytes_to_jax_random_key(key), shape\n",
    "            ))\n",
    "        )(key2, (m,), dtype)\n",
    "    else:\n",
    "        corr_dev2 = dev2(\n",
    "            lambda key, shape, dtype: dtype(-jax.random.bits(\n",
    "                bytes_to_jax_random_key(key), shape\n",
    "            ))\n",
    "        )(key2, (m,), dtype)\n",
    "    return corr_dev1, corr_dev2\n",
    "\n",
    "\n",
    "def cos_sim(u_i, u_j, verbose=False):\n",
    "    # programming details not related to protocol\n",
    "    if verbose:\n",
    "        print(\"input: \", sf.reveal(u_i), sf.reveal(u_j))\n",
    "    \n",
    "    fxp_type = jnp.uint64\n",
    "    shape_ref_i = edge_tees[i](lambda x: x.shape)(u_i.to(edge_tees[i]))\n",
    "    shape_ref_j = edge_tees[j](lambda x: x.shape)(u_j.to(edge_tees[j]))\n",
    "    # let's suppose that the reference type and shape are the same for u_i and u_j and it is ok to share to server\n",
    "    shape_ref_server = shape_ref_i.to(server_tee)\n",
    "\n",
    "    # preprocessing\n",
    "    server_a, edge_tee_i_a = corr(\n",
    "        k, m, server_tee, server_handle_i_s, edge_tees[i], handle_i_s\n",
    "    )\n",
    "    server_b, edge_tee_j_b = corr(\n",
    "        k, m, server_tee, server_handle_j_s, edge_tees[j], handle_j_s\n",
    "    )\n",
    "    c = server_tee(lambda a, b: a * b)(server_a, server_b)\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"preprocessing: \")\n",
    "        print(\"server_a: \", sf.reveal(server_a))\n",
    "        print(\"server_b: \", sf.reveal(server_b))\n",
    "\n",
    "        print(\"edge_tee_i_a: \", sf.reveal(server_a))\n",
    "        print(\"edge_tee_j_b: \", sf.reveal(edge_tee_j_b))\n",
    "        print(\"c: \", sf.reveal(c))\n",
    "    \n",
    "    # normalize u_i and u_j\n",
    "    u_i_normalized = edge_tees[i](\n",
    "        lambda x: jnp.array(x / jnp.linalg.norm(x) * (2.0**fxp), dtype=fxp_type)\n",
    "    )(u_i.to(edge_tees[i]))\n",
    "    u_j_normalized = edge_tees[j](\n",
    "        lambda x: jnp.array(x / jnp.linalg.norm(x) * (2.0**fxp), dtype=fxp_type)\n",
    "    )(u_j.to(edge_tees[j]))\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 1:\")\n",
    "        print(\"fxp\", fxp)\n",
    "        print(\"u_i_normalized\", sf.reveal(u_i_normalized))\n",
    "        print(\"u_j_normalized\", sf.reveal(u_j_normalized))\n",
    "    \n",
    "    # E_i encrypts e = u_i_normalized - a, sends to P_j via P_i\n",
    "    e = edge_tees[i](lambda x, y: x - y)(u_i_normalized, edge_tee_i_a)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 2:\")\n",
    "        print(\"a: \", sf.reveal(edge_tee_i_a))\n",
    "        print(\"e = u_i_normalized - a: \", sf.reveal(e))\n",
    "    \n",
    "    c_e, c_e_tag, c_e_nouce = edge_tees[i](encrypt_jnp_array_gcm, num_returns=3)(\n",
    "        e, handle_i_j\n",
    "    )\n",
    "    c_e_j = c_e.to(edge_devices[i]).to(edge_devices[j])\n",
    "    c_e_tag_j = c_e_tag.to(edge_devices[i]).to(edge_devices[j])\n",
    "    c_e_nouce_j = c_e_nouce.to(edge_devices[i]).to(edge_devices[j])\n",
    "\n",
    "    # E_j encrypts f = u_j_normalized - b, sends to P_i via P_j\n",
    "    f = edge_tees[j](lambda x, y: x - y)(u_j_normalized, edge_tee_j_b)\n",
    "    c_f, c_f_tag, c_f_nouce = edge_tees[j](encrypt_jnp_array_gcm, num_returns=3)(\n",
    "        f, handle_j_i\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 3:\")\n",
    "        print(\"u_j_normalized: \", sf.reveal(u_j_normalized))\n",
    "        print(\"b: \", sf.reveal(edge_tee_j_b))\n",
    "        print(\"f = u_j_normalized - b: \", sf.reveal(f))\n",
    "\n",
    "    c_f_i = c_f.to(edge_devices[j]).to(edge_devices[i])\n",
    "    c_f_tag_i = c_f_tag.to(edge_devices[j]).to(edge_devices[i])\n",
    "    c_f_nouce_i = c_f_nouce.to(edge_devices[j]).to(edge_devices[i])\n",
    "\n",
    "    # P_i decrypts f in E_i\n",
    "    try:\n",
    "        f_dec = edge_tees[i](decrypt_to_jnp_array_gcm)(\n",
    "            c_f_i.to(edge_tees[i]),\n",
    "            c_f_tag_i.to(edge_tees[i]),\n",
    "            c_f_nouce_i.to(edge_tees[i]),\n",
    "            handle_i_j,\n",
    "            fxp_type,\n",
    "            shape_ref_i,\n",
    "        )\n",
    "        sf.wait(f_dec)\n",
    "    except:\n",
    "        raise RuntimeError(\"Error in decrypting f, abort\")\n",
    "\n",
    "    \n",
    "    # P_i decrypts c in E_j\n",
    "    try:\n",
    "        e_dec = edge_tees[j](decrypt_to_jnp_array_gcm)(\n",
    "            c_e_j.to(edge_tees[j]),\n",
    "            c_e_tag_j.to(edge_tees[j]),\n",
    "            c_e_nouce_j.to(edge_tees[j]),\n",
    "            handle_j_i,\n",
    "            fxp_type,\n",
    "            shape_ref_j,\n",
    "        )\n",
    "        sf.wait(e_dec)\n",
    "    except:\n",
    "        raise RuntimeError(\"Error in decrypting c, abort\")\n",
    "\n",
    "    edge_tee_i_a_1, edge_tee_j_a_1 = corr(\n",
    "        k, m, edge_tees[i], handle_i_j, edge_tees[j], handle_j_i\n",
    "    )\n",
    "    edge_tee_i_b_0, edge_tee_j_b_0 = corr(\n",
    "        k, m, edge_tees[i], handle_i_j, edge_tees[j], handle_j_i\n",
    "    )\n",
    "    edge_tee_i_d, edge_tee_j_d = corr(\n",
    "        k, m, edge_tees[i], handle_i_j, edge_tees[j], handle_j_i, True\n",
    "    )\n",
    "    \n",
    "    # lots of question here\n",
    "    edge_tee_i_a_0 = edge_tees[i](lambda x, y: fxp_type(x - y))(edge_tee_i_a, edge_tee_i_a_1)\n",
    "    edge_tee_j_b_1 = edge_tees[j](lambda x, y: fxp_type(x - y))(edge_tee_j_b, edge_tee_j_b_0)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 6:\")\n",
    "        print(\"a_0: \", sf.reveal(edge_tee_i_a_0))\n",
    "        print(\"b_1: \", sf.reveal(edge_tee_j_b_1))\n",
    "        print(\"a_1: \", sf.reveal(edge_tee_i_a_1))\n",
    "        print(\"b_0: \", sf.reveal(edge_tee_j_b_0))\n",
    "        print(\"d_0: \", sf.reveal(edge_tee_i_d))\n",
    "        print(\"d_1: \", sf.reveal(edge_tee_j_d))\n",
    "    \n",
    "       \n",
    "    \n",
    "    # E_i computes:\n",
    "    z_bracket_0 = edge_tees[i](\n",
    "        lambda x1, x2, x3, x4, x5: \n",
    "            fxp_type(fxp_mul(x1, x2))\n",
    "            + fxp_type(fxp_mul(x3, x4))\n",
    "            + fxp_type(fxp_mul(x1, x3))\n",
    "            + fxp_type(x5)\n",
    "    )(e, edge_tee_i_b_0, f_dec, edge_tee_i_a_0, edge_tee_i_d)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 7:\")\n",
    "        print(\"e\", sf.reveal(e))\n",
    "        print(\"f_dec\", sf.reveal(f_dec))\n",
    "        print(\"edge_tee_i_d\", sf.reveal(edge_tee_i_d))\n",
    "        print(\"z_bracket_0\", sf.reveal(z_bracket_0))\n",
    "    \n",
    "    # E_i encrypts z_bracket_0, sends to server tee via server\n",
    "    c_z_bracket_0, c_z_bracket_0_tag, c_z_bracket_0_nouce = edge_tees[i](\n",
    "        encrypt_jnp_array_gcm, num_returns=3\n",
    "    )(z_bracket_0, handle_i_s)\n",
    "    c_z_bracket_0_server = c_z_bracket_0.to(server_device).to(server_tee)\n",
    "    c_z_bracket_0_tag_server = c_z_bracket_0_tag.to(server_device).to(server_tee)\n",
    "    c_z_bracket_0_nouce_server = c_z_bracket_0_nouce.to(server_device).to(server_tee)\n",
    "\n",
    "    # E_j computes:\n",
    "    z_bracket_1 = edge_tees[j](\n",
    "        lambda x1, x2, x3, x4, x5: fxp_type(\n",
    "            fxp_type(fxp_mul(x1, x2))\n",
    "            + fxp_type(fxp_mul(x3, x4))\n",
    "            + fxp_type(x5)\n",
    "        )\n",
    "    )(e_dec, edge_tee_j_b_1, f, edge_tee_j_a_1, edge_tee_j_d)\n",
    "\n",
    "    # E_j encrypts z_bracket_1, sends to server tee via server\n",
    "    c_z_bracket_1, c_z_bracket_1_tag, c_z_bracket_1_nouce = edge_tees[j](\n",
    "        encrypt_jnp_array_gcm, num_returns=3\n",
    "    )(z_bracket_1, handle_j_s)\n",
    "    c_z_bracket_1_server = c_z_bracket_1.to(server_device).to(server_tee)\n",
    "    c_z_bracket_1_tag_server = c_z_bracket_1_tag.to(server_device).to(server_tee)\n",
    "    c_z_bracket_1_nouce_server = c_z_bracket_1_nouce.to(server_device).to(server_tee)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 8:\")\n",
    "        print(\"e_dec\", sf.reveal(e_dec))\n",
    "        print(\"f\", sf.reveal(f))\n",
    "        print(\"edge_tee_j_d\", sf.reveal(edge_tee_j_d))\n",
    "        print(\"z_bracket_1\", sf.reveal(z_bracket_1))\n",
    "    \n",
    "\n",
    "    # server tries to decrypt\n",
    "    try:\n",
    "        z_bracket_0_dec = server_tee(decrypt_to_jnp_array_gcm)(\n",
    "            c_z_bracket_0_server,\n",
    "            c_z_bracket_0_tag_server,\n",
    "            c_z_bracket_0_nouce_server,\n",
    "            server_handle_i_s,\n",
    "            fxp_type,\n",
    "            shape_ref_server,\n",
    "        )\n",
    "        z_bracket_1_dec = server_tee(decrypt_to_jnp_array_gcm)(\n",
    "            c_z_bracket_1_server,\n",
    "            c_z_bracket_1_tag_server,\n",
    "            c_z_bracket_1_nouce_server,\n",
    "            server_handle_j_s,\n",
    "            fxp_type,\n",
    "            shape_ref_server,\n",
    "        )\n",
    "        sf.wait([z_bracket_0_dec, z_bracket_1_dec])\n",
    "    except:\n",
    "        raise Exception(\"Decryption z values failed\")\n",
    "\n",
    "    z = server_tee(lambda x, y: fxp_type(x + y))(z_bracket_0_dec, z_bracket_1_dec)\n",
    "    cos_sim_val = server_tee(\n",
    "            lambda x, y: jnp.sum(fxp_type(x + y))\n",
    "        )(z, c)\n",
    "    \n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"step 10:\")\n",
    "        print(\"z_bracket_0_dec\", sf.reveal(z_bracket_0_dec))\n",
    "        print(\"z_bracket_1_dec\", sf.reveal(z_bracket_1_dec))\n",
    "        print(\"z\", sf.reveal(z))\n",
    "        print(\"c\", sf.reveal(c))\n",
    "        print(\"cos_sim_val\", sf.reveal(cos_sim_val))\n",
    "        print(\"fxp\", fxp)\n",
    "        print(\"cos_sim_val / 2^(2*fxp)\", sf.reveal(cos_sim_val) / (2.**(2*fxp)))\n",
    "    return cos_sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pyu_fn pid=1844138)\u001b[0m 2024-12-13 17:10:35,447,447 INFO [xla_bridge.py:backends:863] Unable to initialize backend 'cuda': \n",
      "\u001b[36m(pyu_fn pid=1844138)\u001b[0m 2024-12-13 17:10:35,448,448 INFO [xla_bridge.py:backends:863] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "\u001b[36m(pyu_fn pid=1844138)\u001b[0m 2024-12-13 17:10:35,448,448 INFO [xla_bridge.py:backends:863] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(pyu_fn pid=1844138)\u001b[0m 2024-12-13 17:10:35,448,448 WARNING [xla_bridge.py:_suggest_missing_backends:901] An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(0.73825558, dtype=float64, weak_type=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.reveal(cos_sim(u_i, u_j)) / (2.**(2*fxp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7382557166568481\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# define two lists or array\n",
    "u_i_revealed = sf.reveal(u_i)\n",
    "u_j_revealed = sf.reveal(u_j)\n",
    "A = u_i_revealed/ norm(u_i_revealed)\n",
    "B = u_j_revealed / norm(u_j_revealed)\n",
    "\n",
    "\n",
    "# compute cosine similarity\n",
    "cosine = np.dot(A, B) / (norm(A) * norm(B))\n",
    "cosine2 = jnp.sum(A * B)\n",
    "print(\"Cosine Similarity:\", cosine2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
