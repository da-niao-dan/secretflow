{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_parties_number = 2\n",
    "edge_party_name = 'edge_party_{i}'\n",
    "edge_parties = [edge_party_name.format(i=i) for i in range(edge_parties_number)]\n",
    "server_party_name = 'server_party'\n",
    "server_party = [server_party_name]\n",
    "all_parties = edge_parties + server_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge_party_0', 'edge_party_1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoupeicheng.zpc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-25 16:53:42,454\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-25 16:53:42,644\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/zoupeicheng.zpc/miniconda3/envs/py310/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2024-11-25 16:53:44,547\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "sf.init(parties=all_parties, address='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_devices = [sf.PYU(edge_party_name.format(i=i)) for i in range(edge_parties_number)]\n",
    "# use pyu to simulate teeu\n",
    "edge_tees = [sf.PYU(edge_party_name.format(i=i)) for i in range(edge_parties_number)]\n",
    "\n",
    "server_device = sf.PYU(server_party_name)\n",
    "server_tee = sf.PYU(server_party_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom parameters\n",
    "i = 0\n",
    "j = 1\n",
    "m = 100\n",
    "kappa = 32\n",
    "u_low = 0.0\n",
    "u_high = 2.0\n",
    "# k is the ring size 2^k. usually take k = 32, 64. like size of int\n",
    "k = 32  # implies use uint32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original JAX Array:\n",
      "[1.543261   1.8819652  1.3520194  0.12602167 0.00819245 0.8335233\n",
      " 0.24762815 0.5973602  0.84210426 1.6452619  0.60468984 1.270024\n",
      " 0.6331784  0.52105224 0.75727856 1.0133526  1.3102268  0.1769932\n",
      " 0.49942148 0.8335648  0.14698231 0.8164377  0.24726874 0.48200187\n",
      " 1.8702365  1.8223263  0.9344147  1.223453   0.00666214 0.9191807\n",
      " 0.9327775  1.5772036  0.3084602  1.7717539  1.491721   0.18190163\n",
      " 1.3147568  0.57207686 0.5401994  1.8854702  0.870894   0.54716337\n",
      " 1.2602699  0.691345   0.72894716 1.5469918  1.9396929  0.6442396\n",
      " 1.54365    0.8659952  0.6514194  1.2232236  1.5714749  0.29944515\n",
      " 0.33028755 0.21620859 0.5635623  1.2797244  0.30582815 0.06229384\n",
      " 0.06313824 0.5007081  0.81141025 0.5239505  0.37149203 1.1353881\n",
      " 0.36785588 0.7070881  0.40961593 1.7803401  1.5857289  0.34309584\n",
      " 1.8364183  1.3298665  0.6180564  0.38195848 0.46578258 1.912777\n",
      " 0.9642606  0.36924857 0.27891305 1.3318433  1.211587   1.987189\n",
      " 1.1710542  1.679124   1.1500549  1.031098   1.8011674  1.1172315\n",
      " 0.938758   0.18980233 0.16563085 1.3590674  0.03411676 0.55324197\n",
      " 1.7490318  0.37986818 1.233613   1.1428924 ]\n",
      "\n",
      "Decrypted JAX Array:\n",
      "[1.543261   1.8819652  1.3520194  0.12602167 0.00819245 0.8335233\n",
      " 0.24762815 0.5973602  0.84210426 1.6452619  0.60468984 1.270024\n",
      " 0.6331784  0.52105224 0.75727856 1.0133526  1.3102268  0.1769932\n",
      " 0.49942148 0.8335648  0.14698231 0.8164377  0.24726874 0.48200187\n",
      " 1.8702365  1.8223263  0.9344147  1.223453   0.00666214 0.9191807\n",
      " 0.9327775  1.5772036  0.3084602  1.7717539  1.491721   0.18190163\n",
      " 1.3147568  0.57207686 0.5401994  1.8854702  0.870894   0.54716337\n",
      " 1.2602699  0.691345   0.72894716 1.5469918  1.9396929  0.6442396\n",
      " 1.54365    0.8659952  0.6514194  1.2232236  1.5714749  0.29944515\n",
      " 0.33028755 0.21620859 0.5635623  1.2797244  0.30582815 0.06229384\n",
      " 0.06313824 0.5007081  0.81141025 0.5239505  0.37149203 1.1353881\n",
      " 0.36785588 0.7070881  0.40961593 1.7803401  1.5857289  0.34309584\n",
      " 1.8364183  1.3298665  0.6180564  0.38195848 0.46578258 1.912777\n",
      " 0.9642606  0.36924857 0.27891305 1.3318433  1.211587   1.987189\n",
      " 1.1710542  1.679124   1.1500549  1.031098   1.8011674  1.1172315\n",
      " 0.938758   0.18980233 0.16563085 1.3590674  0.03411676 0.55324197\n",
      " 1.7490318  0.37986818 1.233613   1.1428924 ]\n",
      "\n",
      "Arrays are equal: True\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from typing import Tuple\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def bytes_to_jax_random_key(byte_key):\n",
    "    # Hash the bytes key using SHA-256\n",
    "    hash_digest = hashlib.sha256(byte_key).digest()\n",
    "\n",
    "    # Convert the first 4 bytes of the hash digest to an integer\n",
    "    # JAX random keys expect a 32-bit integer, hence we use the first 4 bytes\n",
    "    seed = int.from_bytes(hash_digest[:4], 'big')\n",
    "\n",
    "    # Create a JAX random key with this seed\n",
    "    jax_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    return jax_key\n",
    "\n",
    "\n",
    "# Function to encrypt a jnp array using AES-GCM\n",
    "def encrypt_jnp_array_gcm(jnp_array, key) -> Tuple[bytes, bytes, bytes]:\n",
    "    # Convert jnp array to numpy array\n",
    "    np_array = np.array(jnp_array)\n",
    "\n",
    "    # Convert numpy array to bytes\n",
    "    array_bytes = np_array.tobytes()\n",
    "\n",
    "    # Create AES cipher in GCM mode\n",
    "    cipher = AES.new(key, AES.MODE_GCM)\n",
    "\n",
    "    # Encrypt data\n",
    "    ciphertext, tag = cipher.encrypt_and_digest(array_bytes)\n",
    "\n",
    "    # Return the ciphertext, tag, and nonce\n",
    "    return ciphertext, tag, cipher.nonce\n",
    "\n",
    "\n",
    "# Function to decrypt a jnp array using AES-GCM\n",
    "def decrypt_to_jnp_array_gcm(ciphertext, tag, nonce, key, dtype, shape):\n",
    "    # Create AES cipher in GCM mode with the same parameters\n",
    "    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n",
    "\n",
    "    # Decrypt data\n",
    "    decrypted_data = cipher.decrypt_and_verify(ciphertext, tag)\n",
    "\n",
    "    # Convert bytes back to numpy array\n",
    "    decrypted_np_array = np.frombuffer(decrypted_data, dtype=dtype).reshape(shape)\n",
    "\n",
    "    # Convert numpy array to jnp array\n",
    "    decrypted_jnp_array = jnp.array(decrypted_np_array)\n",
    "\n",
    "    return decrypted_jnp_array\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a random key for AES-256 (32 bytes)\n",
    "    key = get_random_bytes(32)\n",
    "\n",
    "    # Create a jnp array\n",
    "    original_jnp_array = jnp.array(np.random.uniform(u_low, u_high, (m,)))\n",
    "\n",
    "    # Encrypt the jnp array using AES-GCM\n",
    "    ciphertext, tag, nonce = encrypt_jnp_array_gcm(original_jnp_array, key)\n",
    "\n",
    "    # Decrypt to a jnp array\n",
    "    decrypted_jnp_array = decrypt_to_jnp_array_gcm(\n",
    "        ciphertext, tag, nonce, key, dtype=jnp.float32, shape=original_jnp_array.shape\n",
    "    )\n",
    "\n",
    "    # Check if the original and decrypted arrays are the same\n",
    "    print(\"Original JAX Array:\")\n",
    "    print(original_jnp_array)\n",
    "    print(\"\\nDecrypted JAX Array:\")\n",
    "    print(decrypted_jnp_array)\n",
    "    print(\n",
    "        \"\\nArrays are equal:\", jnp.array_equal(original_jnp_array, decrypted_jnp_array)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "# Simulate handles\n",
    "\n",
    "handle_i_j = edge_tees[i](lambda x: get_random_bytes(x))(kappa)\n",
    "handle_i_s = edge_tees[i](lambda x: get_random_bytes(x))(kappa)\n",
    "\n",
    "# note that the establishment is not simplified.\n",
    "handle_j_i = handle_i_j.to(edge_tees[j])\n",
    "handle_j_s = edge_tees[j](lambda x: get_random_bytes(x))(kappa)\n",
    "\n",
    "server_handle_i_s = handle_i_s.to(server_tee)\n",
    "server_handle_j_s = handle_j_s.to(server_tee)\n",
    "\n",
    "\n",
    "# P_i holds u_i\n",
    "u_i = edge_devices[i](lambda x: x)(jnp.array(np.random.uniform(u_low, u_high, (m,))))\n",
    "\n",
    "# P_j holds u_j\n",
    "u_j = edge_devices[j](lambda x: x)(jnp.array(np.random.uniform(u_low, u_high, (m,))))\n",
    "\n",
    "\n",
    "# corr preprocessing\n",
    "def corr(k, m, dev1, key1, dev2, key2, return_zero_sharing=False):\n",
    "    \"\"\"Correlation function\n",
    "\n",
    "    Args:\n",
    "        k (int): ring size will be 2^k. Support k = 64 or 128 for now\n",
    "        m (int): size of array to be correlated\n",
    "        dev1 (Device): device 1\n",
    "        key1 (Key): key for device 1\n",
    "        dev2 (Device): device 2\n",
    "        key2 (Key): key for device 2, key2 must be the same as key1 yet hold by different device\n",
    "    \"\"\"\n",
    "    assert k == 32, \"Only support k = 32 for now\"\n",
    "    dtype = jnp.uint32\n",
    "    corr_dev1 = dev1(\n",
    "        lambda key, shape, dtype: jax.random.bits(\n",
    "            bytes_to_jax_random_key(key), shape, dtype\n",
    "        )\n",
    "    )(key1, (m,), dtype)\n",
    "    if not return_zero_sharing:\n",
    "        corr_dev2 = dev2(\n",
    "            lambda key, shape, dtype: jax.random.bits(\n",
    "                bytes_to_jax_random_key(key), shape, dtype\n",
    "            )\n",
    "        )(key2, (m,), dtype)\n",
    "    else:\n",
    "        corr_dev2 = dev2(\n",
    "            lambda key, shape, dtype: -jax.random.bits(\n",
    "                bytes_to_jax_random_key(key), shape, dtype\n",
    "            )\n",
    "        )(key2, (m,), dtype)\n",
    "    return corr_dev1, corr_dev2\n",
    "\n",
    "\n",
    "def cos_sim(u_i, u_j):\n",
    "    # proramming details not related to protocol\n",
    "    dtype_ref_i = edge_tees[i](lambda x: x.dtype)(u_i.to(edge_tees[i]))\n",
    "    shape_ref_i = edge_tees[i](lambda x: x.shape)(u_i.to(edge_tees[i]))\n",
    "    dtype_ref_j = edge_tees[j](lambda x: x.dtype)(u_j.to(edge_tees[j]))\n",
    "    shape_ref_j = edge_tees[j](lambda x: x.shape)(u_j.to(edge_tees[j]))\n",
    "    # let's suppose that the reference type and shape are the same for u_i and u_j and it is ok to share to server\n",
    "    dtype_ref_server = dtype_ref_i.to(server_tee)\n",
    "    shape_ref_server = shape_ref_i.to(server_tee)\n",
    "\n",
    "    # preprocessing\n",
    "    server_a, edge_tee_i_a = corr(\n",
    "        k, m, server_tee, server_handle_i_s, edge_tees[i], handle_i_s\n",
    "    )\n",
    "    server_b, edge_tee_j_b = corr(\n",
    "        k, m, server_tee, server_handle_j_s, edge_tees[j], handle_j_s\n",
    "    )\n",
    "    c = server_tee(lambda a, b: a * b)(server_a, server_b)\n",
    "\n",
    "    # normalize u_i and u_j\n",
    "    u_i_normalized = edge_tees[i](lambda x: x / jnp.linalg.norm(x))(\n",
    "        u_i.to(edge_tees[i])\n",
    "    )\n",
    "    u_j_normalized = edge_tees[j](lambda x: x / jnp.linalg.norm(x))(\n",
    "        u_j.to(edge_tees[j])\n",
    "    )\n",
    "\n",
    "    # E_i encrypts e = u_i_normalized - a, sends to P_j via P_i\n",
    "    e = edge_tees[i](lambda x, y: x - y)(u_i_normalized, edge_tee_i_a)\n",
    "    c_e, c_e_tag, c_e_nouce = edge_tees[i](encrypt_jnp_array_gcm, num_returns=3)(\n",
    "        e, handle_i_j\n",
    "    )\n",
    "    c_e_j = c_e.to(edge_devices[i]).to(edge_devices[j])\n",
    "    c_e_tag_j = c_e_tag.to(edge_devices[i]).to(edge_devices[j])\n",
    "    c_e_nouce_j = c_e_nouce.to(edge_devices[i]).to(edge_devices[j])\n",
    "\n",
    "    # E_j encrypts f = u_j_normalized - b, sends to P_i via P_j\n",
    "    f = edge_tees[j](lambda x, y: x - y)(u_j_normalized, edge_tee_j_b)\n",
    "    c_f, c_f_tag, c_f_nouce = edge_tees[j](encrypt_jnp_array_gcm, num_returns=3)(\n",
    "        f, handle_j_i\n",
    "    )\n",
    "\n",
    "    c_f_i = c_f.to(edge_devices[j]).to(edge_devices[i])\n",
    "    c_f_tag_i = c_f_tag.to(edge_devices[j]).to(edge_devices[i])\n",
    "    c_f_nouce_i = c_f_nouce.to(edge_devices[j]).to(edge_devices[i])\n",
    "\n",
    "    # P_i decrypts f in E_i\n",
    "    try:\n",
    "        f_dec = edge_tees[i](decrypt_to_jnp_array_gcm)(\n",
    "            c_f_i.to(edge_tees[i]),\n",
    "            c_f_tag_i.to(edge_tees[i]),\n",
    "            c_f_nouce_i.to(edge_tees[i]),\n",
    "            handle_i_j,\n",
    "            dtype_ref_i,\n",
    "            shape_ref_i,\n",
    "        )\n",
    "        sf.wait(f_dec)\n",
    "    except:\n",
    "        raise RuntimeError(\"Error in decrypting f, abort\")\n",
    "\n",
    "    # P_i decrypts c in E_j\n",
    "    try:\n",
    "        e_dec = edge_tees[j](decrypt_to_jnp_array_gcm)(\n",
    "            c_e_j.to(edge_tees[j]),\n",
    "            c_e_tag_j.to(edge_tees[j]),\n",
    "            c_e_nouce_j.to(edge_tees[j]),\n",
    "            handle_j_i,\n",
    "            dtype_ref_j,\n",
    "            shape_ref_j,\n",
    "        )\n",
    "        sf.wait(e_dec)\n",
    "    except:\n",
    "        raise RuntimeError(\"Error in decrypting c, abort\")\n",
    "\n",
    "    edge_tee_i_u_i_bracket_1, edge_tee_j_u_i_bracket_1 = corr(\n",
    "        k, m, edge_tees[i], handle_i_j, edge_tees[j], handle_j_i\n",
    "    )\n",
    "    edge_tee_i_u_j_bracket_0, edge_tee_j_u_j_bracket_0 = corr(\n",
    "        k, m, edge_tees[i], handle_i_j, edge_tees[j], handle_j_i\n",
    "    )\n",
    "    edge_tee_i_d, edge_tee_j_d = corr(\n",
    "        k, m, edge_tees[i], handle_i_j, edge_tees[j], handle_j_i, True\n",
    "    )\n",
    "\n",
    "    u_i_bracket_0 = edge_tees[i](lambda x, y: x - y)(u_i, edge_tee_i_u_i_bracket_1)\n",
    "    u_j_bracket_1 = edge_tees[j](lambda x, y: x - y)(u_j, edge_tee_j_u_j_bracket_0)\n",
    "\n",
    "    # E_i computes:\n",
    "    z_bracket_0 = edge_tees[i](\n",
    "        lambda x1, x2, x3, x4, x5: x1 * x2 + x3 * x4 + x1 * x3 + x5\n",
    "    )(e, edge_tee_i_u_j_bracket_0, f_dec, u_i_bracket_0, edge_tee_i_d)\n",
    "\n",
    "    # E_i encrypts z_bracket_0, sends to server tee via server\n",
    "    c_z_bracket_0, c_z_bracket_0_tag, c_z_bracket_0_nouce = edge_tees[i](\n",
    "        encrypt_jnp_array_gcm, num_returns=3\n",
    "    )(z_bracket_0, handle_i_s)\n",
    "    c_z_bracket_0_server = c_z_bracket_0.to(server_device).to(server_tee)\n",
    "    c_z_bracket_0_tag_server = c_z_bracket_0_tag.to(server_device).to(server_tee)\n",
    "    c_z_bracket_0_nouce_server = c_z_bracket_0_nouce.to(server_device).to(server_tee)\n",
    "\n",
    "    # E_j computes:\n",
    "    z_bracket_1 = edge_tees[j](lambda x1, x2, x3, x4, x5: x1 * x2 + x3 * x4 + x5)(\n",
    "        e_dec, u_j_bracket_1, f, edge_tee_j_u_i_bracket_1, edge_tee_j_d\n",
    "    )\n",
    "\n",
    "    # E_j encrypts z_bracket_1, sends to server tee via server\n",
    "    c_z_bracket_1, c_z_bracket_1_tag, c_z_bracket_1_nouce = edge_tees[j](\n",
    "        encrypt_jnp_array_gcm, num_returns=3\n",
    "    )(z_bracket_1, handle_j_s)\n",
    "    c_z_bracket_1_server = c_z_bracket_1.to(server_device).to(server_tee)\n",
    "    c_z_bracket_1_tag_server = c_z_bracket_1_tag.to(server_device).to(server_tee)\n",
    "    c_z_bracket_1_nouce_server = c_z_bracket_1_nouce.to(server_device).to(server_tee)\n",
    "\n",
    "    # server tries to decrypt\n",
    "    try:\n",
    "        z_bracket_0_dec = server_tee(decrypt_to_jnp_array_gcm)(\n",
    "            c_z_bracket_0_server,\n",
    "            c_z_bracket_0_tag_server,\n",
    "            c_z_bracket_0_nouce_server,\n",
    "            server_handle_i_s,\n",
    "            dtype_ref_server,\n",
    "            shape_ref_server,\n",
    "        )\n",
    "        z_bracket_1_dec = server_tee(decrypt_to_jnp_array_gcm)(\n",
    "            c_z_bracket_1_server,\n",
    "            c_z_bracket_1_tag_server,\n",
    "            c_z_bracket_1_nouce_server,\n",
    "            server_handle_j_s,\n",
    "            dtype_ref_server,\n",
    "            shape_ref_server,\n",
    "        )\n",
    "        sf.wait([z_bracket_0_dec, z_bracket_1_dec])\n",
    "    except:\n",
    "        raise Exception(\"Decryption z values failed\")\n",
    "\n",
    "    z = server_tee(lambda x, y: x + y)(z_bracket_0_dec, z_bracket_1_dec)\n",
    "    cos_sim_val = server_tee(lambda x, y: jnp.sum(x + y))(z, c)\n",
    "    return cos_sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pyu_fn pid=758380)\u001b[0m An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(pyu_fn pid=758376)\u001b[0m 2024-11-25 16:53:46,843,843 INFO [xla_bridge.py:backends:863] Unable to initialize backend 'cuda': \n",
      "\u001b[36m(pyu_fn pid=758376)\u001b[0m 2024-11-25 16:53:46,843,843 INFO [xla_bridge.py:backends:863] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "\u001b[36m(pyu_fn pid=758376)\u001b[0m 2024-11-25 16:53:46,844,844 INFO [xla_bridge.py:backends:863] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
      "\u001b[36m(pyu_fn pid=758376)\u001b[0m 2024-11-25 16:53:46,844,844 WARNING [xla_bridge.py:_suggest_missing_backends:901] An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(5.5957816e+20, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.reveal(cos_sim(u_i, u_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
